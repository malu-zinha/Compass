import React, { useState, useRef, useEffect } from 'react';
import { useNavigate, useLocation } from 'react-router-dom';
import { generateAnalysis, updateInterviewNotes, getInterviewById, getGlobalQuestions } from '../services/api';
import { useRealtimeTranscription } from '../hooks/useRealtimeTranscription';
import { InfoIcon, FileTextIcon, BriefcaseIcon } from '../components/icons';
import './RecordPage.css';

function RecordPage() {
  const navigate = useNavigate();
  const location = useLocation();
  
  // Dados passados pela p√°gina anterior
  const [interviewId, setInterviewId] = useState(null);
  const [candidateData, setCandidateData] = useState(null);
  
  // Grava√ß√£o
  const [isRecording, setIsRecording] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const mediaRecorderRef = useRef(null);
  const timerIntervalRef = useRef(null);
  const streamRef = useRef(null);
  const audioContextRef = useRef(null);
  const processorNodeRef = useRef(null);
  const isRecordingRef = useRef(false);
  const audioChunksRef = useRef([]);
  
  // Transcri√ß√£o em tempo real via WebSocket (SEM diariza√ß√£o completa)
  // NOTA: Esta transcri√ß√£o √© TEMPOR√ÅRIA e ser√° SUBSTITU√çDA pela transcri√ß√£o
  // com diariza√ß√£o completa ap√≥s o upload do √°udio ao finalizar a entrevista
  const { transcripts, questions: aiQuestions, isConnected, sendAudioChunk } = useRealtimeTranscription(interviewId);
  
  // Perguntas cadastradas (globais + espec√≠ficas do cargo)
  const [registeredQuestions, setRegisteredQuestions] = useState([]);
  const [loadingQuestions, setLoadingQuestions] = useState(false);
  
  // Perguntas combinadas (AI + pr√©-programadas)
  const [selectedQuestionId, setSelectedQuestionId] = useState(null);
  
  // Anota√ß√µes
  const [notes, setNotes] = useState('');
  
  // Estado de processamento
  const [isProcessing, setIsProcessing] = useState(false);
  const [processingMessage, setProcessingMessage] = useState('');
  
  // Fun√ß√£o de cleanup completa para garantir que o microfone seja desligado
  // Fun√ß√£o para enviar √°udio para o backend
  const uploadAudioToBackend = async () => {
    if (audioChunksRef.current.length === 0) {
      console.warn('Nenhum √°udio gravado para enviar');
      return false;
    }

    try {
      console.log(`Enviando ${audioChunksRef.current.length} chunks de √°udio para o backend...`);
      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
      console.log('Tamanho do √°udio:', audioBlob.size, 'bytes');
      console.log('Dura√ß√£o da grava√ß√£o:', recordingTime, 'segundos');
      
      const formData = new FormData();
      formData.append('audio', audioBlob, `interview_${interviewId}.webm`);
      // Enviar tamb√©m a dura√ß√£o da grava√ß√£o para o backend usar como metadata
      formData.append('duration', recordingTime.toString());
      
      const response = await fetch(`http://localhost:8000/positions/interviews/${interviewId}/upload-audio`, {
        method: 'POST',
        body: formData
      });
      
      if (!response.ok) {
        throw new Error(`Erro ao enviar √°udio: ${response.status}`);
      }
      
      console.log('‚úÖ √Åudio enviado com sucesso para o backend');
      console.log('‚úÖ Dura√ß√£o enviada:', recordingTime, 'segundos');
      audioChunksRef.current = []; // Limpar chunks ap√≥s envio
      return true;
    } catch (error) {
      console.error('‚ùå Erro ao enviar √°udio:', error);
      return false;
    }
  };

  const cleanupAllResources = () => {
    console.log('Limpando todos os recursos de √°udio...');
    
    // Parar grava√ß√£o
    isRecordingRef.current = false;
    
    // Parar MediaRecorder
    if (mediaRecorderRef.current) {
      try {
        if (mediaRecorderRef.current.state !== 'inactive') {
          mediaRecorderRef.current.stop();
        }
      } catch (e) {
        console.warn('Erro ao parar MediaRecorder:', e);
      }
      mediaRecorderRef.current = null;
    }
    
    // Desconectar e limpar processor
    if (processorNodeRef.current) {
      try {
        processorNodeRef.current.disconnect();
      } catch (e) {
        console.warn('Erro ao desconectar processor:', e);
      }
      processorNodeRef.current = null;
    }
    
    // Fechar AudioContext
    if (audioContextRef.current) {
      try {
        if (audioContextRef.current.state !== 'closed') {
          audioContextRef.current.close();
        }
      } catch (e) {
        console.warn('Erro ao fechar AudioContext:', e);
      }
      audioContextRef.current = null;
    }
    
    // Parar todas as tracks do stream
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => {
        track.stop();
        console.log('Track parada:', track.kind);
      });
      streamRef.current = null;
    }
    
    // Parar timer
    if (timerIntervalRef.current) {
      clearInterval(timerIntervalRef.current);
      timerIntervalRef.current = null;
    }
    
    setIsRecording(false);
    console.log('Recursos de √°udio limpos');
  };

  // Inicializa√ß√£o
  useEffect(() => {
    // Pegar dados do state da navega√ß√£o
    if (location.state?.interviewId && location.state?.candidateData) {
      setInterviewId(location.state.interviewId);
      setCandidateData(location.state.candidateData);
      console.log('Interview ID recebido:', location.state.interviewId);
    } else {
      // Fallback: tentar localStorage
      const savedData = localStorage.getItem('interviewData');
      if (!savedData) {
        alert('Dados da entrevista n√£o encontrados');
        navigate('/nova-entrevista');
        return;
      }
      setCandidateData(JSON.parse(savedData));
    }
    
    // Listener para quando o usu√°rio tenta sair da p√°gina
    const handleBeforeUnload = (e) => {
      cleanupAllResources();
    };
    
    // Listener para quando o usu√°rio navega (popstate - bot√£o voltar)
    const handlePopState = () => {
      cleanupAllResources();
    };
    
    window.addEventListener('beforeunload', handleBeforeUnload);
    window.addEventListener('popstate', handlePopState);
    
    // Cleanup quando componente √© desmontado
    return () => {
      window.removeEventListener('beforeunload', handleBeforeUnload);
      window.removeEventListener('popstate', handlePopState);
      cleanupAllResources();
    };
  }, [location, navigate]);

  // Carregar perguntas cadastradas quando tiver interviewId e position_id
  useEffect(() => {
    const loadRegisteredQuestions = async () => {
      if (!candidateData?.candidatePositionId) {
        return;
      }
      
      setLoadingQuestions(true);
      try {
        // Carregar perguntas globais (sem position_id)
        const globalQuestions = await getGlobalQuestions(null);
        
        // Carregar perguntas espec√≠ficas do cargo (com position_id)
        const positionQuestions = await getGlobalQuestions(candidateData.candidatePositionId);
        
        // Combinar todas as perguntas cadastradas
        const allRegistered = [
          ...globalQuestions.map(q => ({
            id: `global-${q.id}`,
            text: q.question,
            isAI: false,
            isGlobal: true
          })),
          ...positionQuestions.map(q => ({
            id: `position-${q.id}`,
            text: q.question,
            isAI: false,
            isGlobal: false
          }))
        ];
        
        setRegisteredQuestions(allRegistered);
        console.log(`Carregadas ${allRegistered.length} perguntas cadastradas (${globalQuestions.length} globais + ${positionQuestions.length} do cargo)`);
      } catch (error) {
        console.error('Erro ao carregar perguntas cadastradas:', error);
        setRegisteredQuestions([]);
      } finally {
        setLoadingQuestions(false);
      }
    };
    
    loadRegisteredQuestions();
  }, [candidateData?.candidatePositionId]);

  // Auto-start recording quando tiver interviewId
  useEffect(() => {
    if (interviewId && !isRecording) {
      startRecording();
    }
  }, [interviewId]);
  
  // Timer
  useEffect(() => {
    if (isRecording) {
      timerIntervalRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1);
      }, 1000);
    } else {
      if (timerIntervalRef.current) {
        clearInterval(timerIntervalRef.current);
      }
    }
    
    return () => {
      if (timerIntervalRef.current) {
        clearInterval(timerIntervalRef.current);
      }
    };
  }, [isRecording]);

  // Fun√ß√£o para converter Float32Array para PCM16 (Int16Array)
  const convertToPCM16 = (float32Array) => {
    const int16Array = new Int16Array(float32Array.length);
    for (let i = 0; i < float32Array.length; i++) {
      // Clamp entre -1 e 1, depois multiplica por 32767
      const s = Math.max(-1, Math.min(1, float32Array[i]));
      int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
    }
    return int16Array.buffer;
  };

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          channelCount: 1, // Mono
          sampleRate: 16000, // 16kHz
          echoCancellation: true,
          noiseSuppression: true
        }
      });
      streamRef.current = stream;
      
      // Criar AudioContext para processar √°udio
      const audioContext = new (window.AudioContext || window.webkitAudioContext)({
        sampleRate: 16000
      });
      audioContextRef.current = audioContext;

      // Criar source node do stream
      const source = audioContext.createMediaStreamSource(stream);
      
      // Criar ScriptProcessorNode para processar √°udio (4096 samples = ~256ms a 16kHz)
      const bufferSize = 4096;
      const processor = audioContext.createScriptProcessor(bufferSize, 1, 1);
      processorNodeRef.current = processor;

      processor.onaudioprocess = (e) => {
        if (!isRecordingRef.current) return;
        
        const inputData = e.inputBuffer.getChannelData(0);
        // Converter para PCM16 e enviar
        const pcmData = convertToPCM16(inputData);
        sendAudioChunk(pcmData);
      };

      // Conectar nodes
      source.connect(processor);
      processor.connect(audioContext.destination);

      // Tamb√©m salvar em WebM para arquivo final
      const options = { mimeType: 'audio/webm;codecs=opus' };
      const mediaRecorder = new MediaRecorder(stream, options);
      mediaRecorderRef.current = mediaRecorder;

      mediaRecorder.ondataavailable = (e) => {
        if (e.data && e.data.size > 0) {
          console.log('√Åudio chunk recebido:', e.data.size, 'bytes');
          audioChunksRef.current.push(e.data);
        }
      };

      // Capturar dados a cada 1 segundo para salvar arquivo
      mediaRecorder.start(1000);
      isRecordingRef.current = true;
      setIsRecording(true);
      console.log('Grava√ß√£o iniciada');
    } catch (error) {
      console.error('Erro ao acessar microfone:', error);
      alert('Erro ao acessar o microfone. Verifique as permiss√µes.');
    }
  };

  const stopRecording = () => {
    cleanupAllResources();
  };


  
  const formatTime = (seconds) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${String(mins).padStart(2, '0')}:${String(secs).padStart(2, '0')}`;
  };

  // Fun√ß√£o para verificar se a transcri√ß√£o est√° pronta (com retry otimizado)
  const waitForTranscript = async (maxRetries = 5, delayMs = 500) => {
    for (let i = 0; i < maxRetries; i++) {
      try {
        setProcessingMessage(`Aguardando transcri√ß√£o... (${i + 1}/${maxRetries})`);
        const interview = await getInterviewById(interviewId);
        // Verificar se transcript existe e n√£o est√° vazio (pode ser array ou string JSON)
        if (interview.transcript) {
          let transcriptData = interview.transcript;
          // Se for string, tentar fazer parse
          if (typeof transcriptData === 'string' && transcriptData.trim()) {
            try {
              transcriptData = JSON.parse(transcriptData);
            } catch (e) {
              // Se n√£o for JSON v√°lido, considerar como vazio
              transcriptData = null;
            }
          }
          // Verificar se √© array e tem elementos
          if (Array.isArray(transcriptData) && transcriptData.length > 0) {
            console.log('Transcri√ß√£o encontrada!');
            return true;
          }
        }
      } catch (error) {
        console.log(`Tentativa ${i + 1}/${maxRetries}: Transcri√ß√£o ainda n√£o dispon√≠vel...`);
      }
      
      if (i < maxRetries - 1) {
        await new Promise(resolve => setTimeout(resolve, delayMs));
      }
    }
    return false;
  };

  const handleEndInterview = async () => {
    if (!interviewId) {
      alert('ID da entrevista n√£o encontrado!');
      return;
    }

    setIsProcessing(true);
    const startTotal = Date.now();
    
    console.log('\n' + '='.repeat(80));
    console.log('‚è±Ô∏è  INICIANDO FINALIZA√á√ÉO DA ENTREVISTA');
    console.log('='.repeat(80) + '\n');
    
    try {
      // 1. Parar grava√ß√£o (mas n√£o limpar recursos ainda)
      console.log('[1/6] Parando grava√ß√£o...');
      const startStop = Date.now();
      setProcessingMessage('Parando grava√ß√£o...');
      isRecordingRef.current = false;
      setIsRecording(false);
      
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
        mediaRecorderRef.current.stop();
        // Aguardar para garantir que ondataavailable seja chamado
        await new Promise(resolve => setTimeout(resolve, 500));
      }
      console.log(`‚è±Ô∏è  [1/6] Grava√ß√£o parada em ${((Date.now() - startStop) / 1000).toFixed(2)}s`);
      
      // 2. Enviar √°udio para o backend
      console.log('[2/6] Enviando √°udio para o servidor...');
      console.log('üìù O backend ir√° processar o √°udio COM DIARIZA√á√ÉO em background');
      console.log('üìù Esta transcri√ß√£o com diariza√ß√£o substituir√° a transcri√ß√£o em tempo real');
      const startUpload = Date.now();
      setProcessingMessage('Enviando √°udio para o servidor (ser√° processado com diariza√ß√£o)...');
      const audioSent = await uploadAudioToBackend();
      if (!audioSent) {
        console.warn('‚ö†Ô∏è Falha ao enviar √°udio, mas continuando com a an√°lise...');
      } else {
        console.log(`‚è±Ô∏è  [2/6] √Åudio enviado em ${((Date.now() - startUpload) / 1000).toFixed(2)}s`);
        console.log('‚úÖ Backend iniciar√° transcri√ß√£o COM DIARIZA√á√ÉO em background');
      }
      
      // 3. Limpar recursos de √°udio
      console.log('[3/6] Limpando recursos de √°udio...');
      cleanupAllResources();
      console.log('‚úÖ [3/6] Recursos limpos');
      
      // 4. Salvar anota√ß√µes
      if (notes.trim()) {
        console.log('[4/6] Salvando anota√ß√µes...');
        const startNotes = Date.now();
        setProcessingMessage('Salvando anota√ß√µes...');
        await updateInterviewNotes(interviewId, notes);
        console.log(`‚è±Ô∏è  [4/6] Anota√ß√µes salvas em ${((Date.now() - startNotes) / 1000).toFixed(2)}s`);
      } else {
        console.log('[4/6] Sem anota√ß√µes para salvar');
      }
      
      // 5. Aguardar transcri√ß√£o estar pronta
      console.log('[5/6] Aguardando transcri√ß√£o estar pronta...');
      const startWait = Date.now();
      setProcessingMessage('Aguardando transcri√ß√£o...');
      const transcriptReady = await waitForTranscript(5, 500);
      
      if (!transcriptReady) {
        console.warn('‚ö†Ô∏è Transcri√ß√£o n√£o encontrada ap√≥s v√°rias tentativas');
        console.warn('‚ö†Ô∏è O backend ir√° transcrever o √°udio durante a an√°lise');
        setProcessingMessage('Preparando para an√°lise...');
      } else {
        console.log(`‚úÖ [5/6] Transcri√ß√£o confirmada em ${((Date.now() - startWait) / 1000).toFixed(2)}s`);
      }
      
      // 6. Gerar an√°lise
      console.log('[6/6] Gerando an√°lise com IA...');
      setProcessingMessage('Gerando an√°lise e resumo... (isso pode levar alguns minutos)');
      const startAnalysis = Date.now();
      await generateAnalysis(interviewId);
      const analysisTime = ((Date.now() - startAnalysis) / 1000).toFixed(2);
      console.log(`‚è±Ô∏è  [6/6] An√°lise gerada em ${analysisTime}s`);
      
      // Clean up
      localStorage.removeItem('interviewData');
      
      // Garantir que recursos est√£o limpos antes de navegar
      cleanupAllResources();
      
      const totalTime = ((Date.now() - startTotal) / 1000).toFixed(2);
      console.log('\n' + '='.repeat(80));
      console.log(`‚è±Ô∏è  TEMPO TOTAL: ${totalTime}s`);
      console.log('='.repeat(80) + '\n');
      
      // Navegar para a p√°gina de detalhes
      setIsProcessing(false);
      navigate(`/entrevista/${interviewId}`);

    } catch (error) {
      console.error('Erro ao processar entrevista:', error);
      setIsProcessing(false);
      setProcessingMessage('');
      // Garantir cleanup mesmo em caso de erro
      cleanupAllResources();
      alert(`Erro ao processar entrevista: ${error.message}\n\nMas os dados foram salvos. ID: ${interviewId}`);
      navigate('/inicio');
    }
  };

  // Combinar todas as perguntas: cadastradas (globais + espec√≠ficas) + IA
  const allQuestions = [
    ...registeredQuestions,
    ...aiQuestions
  ];

  if (!candidateData) {
    return <div>Carregando...</div>;
  }

  return (
    <div className="record-page-container">
      {/* Transcri√ß√£o Panel */}
      <div className="transcription-panel">
        <div className="transcription-card">
          <h3>
            Transcri√ß√£o 
            {isConnected && <span style={{color: '#16a34a', fontSize: '0.8rem', marginLeft: '0.5rem'}}>‚óè AO VIVO</span>}
            {isRecording && !isConnected && <span style={{color: '#eab308', fontSize: '0.8rem', marginLeft: '0.5rem'}}>‚ö† Conectando...</span>}
          </h3>
          <div className="transcription-content">
            {transcripts.length > 0 && transcripts
              .map((item, index) => {
                // Normalizar speaker para mai√∫scula
                const speaker = String(item.speaker || 'A').toUpperCase();
                const speakerLabel = speaker === 'A' ? 'Pessoa 1' : 'Pessoa 2';
                const isPersonOne = speaker === 'A';
                // Usar id se dispon√≠vel, sen√£o usar index como fallback
                const key = item.id || `transcript-${index}`;
                
                return (
                  <div key={key} className={`transcription-message ${isPersonOne ? 'message-left' : 'message-right'}`}>
                    <div className="message-speaker">{speakerLabel}</div>
                    <div className={`transcription-bubble ${isPersonOne ? 'candidato' : 'entrevistador'} ${item.is_final ? '' : 'transcribing'}`}>
                      {item.text}
                      {!item.is_final && <span className="typing-indicator">...</span>}
                    </div>
                  </div>
                );
              })
            }
          </div>
        </div>
      </div>
      
      {/* Right Panel */}
      <div className="right-panel">
        {/* Questions Section */}
        <div className="questions-section">
          <h3>Perguntas</h3>
          
          <div className="questions-list">
            {loadingQuestions && (
              <p style={{ textAlign: 'center', color: '#6b7280', fontSize: '0.9rem' }}>
                Carregando perguntas...
              </p>
            )}
            {!loadingQuestions && allQuestions.length === 0 && (
              <p style={{ textAlign: 'center', color: '#6b7280', fontSize: '0.9rem' }}>
                {isConnected ? 'Sugest√µes de perguntas aparecer√£o aqui...' : 'Aguardando sugest√µes de perguntas...'}
              </p>
            )}
            {allQuestions.map((question) => (
              <div
                key={question.id}
                className={`question-item ${selectedQuestionId === question.id ? 'selected' : ''}`}
                onClick={() => setSelectedQuestionId(question.id)}
              >
                <div className="question-header">
                  <div className="question-number-status">
                    <span className="question-number">
                      {question.isAI ? (
                        <>
                          <InfoIcon size={16} color="#371C68" />
                          IA
                        </>
                      ) : question.isGlobal ? (
                        <>
                          <FileTextIcon size={16} color="#371C68" />
                          Geral
                        </>
                      ) : (
                        <>
                          <BriefcaseIcon size={16} color="#371C68" />
                          Cargo
                        </>
                      )}
                    </span>
                  </div>
                </div>
                
                <p className="question-text">{question.text}</p>
              </div>
            ))}
          </div>
        </div>
        
        {/* Notes Section */}
        <div className="notes-section">
          <h3>Anota√ß√µes</h3>
          <textarea
            className="notes-textarea"
            value={notes}
            onChange={(e) => setNotes(e.target.value)}
            placeholder="Aqui ser√£o anotados detalhes adicionais sobre a entrevista!"
          />
        </div>
      </div>
      
      {/* Footer */}
      <div className="footer-controls">
        <div className="timer">
          {formatTime(recordingTime)}
        </div>
        <button 
          className="end-interview-btn"
          onClick={handleEndInterview}
          disabled={!interviewId || isProcessing}
        >
          {isProcessing ? processingMessage || 'Processando...' : 'Encerrar grava√ß√£o'}
        </button>
      </div>
      
      {/* Overlay de processamento */}
      {isProcessing && (
        <div style={{
          position: 'fixed',
          top: 0,
          left: 0,
          right: 0,
          bottom: 0,
          backgroundColor: 'rgba(0, 0, 0, 0.5)',
          display: 'flex',
          alignItems: 'center',
          justifyContent: 'center',
          zIndex: 9999
        }}>
          <div style={{
            backgroundColor: 'white',
            padding: '2rem',
            borderRadius: '8px',
            textAlign: 'center',
            minWidth: '300px'
          }}>
            <div style={{ marginBottom: '1rem' }}>
              <div style={{
                border: '4px solid #f3f3f3',
                borderTop: '4px solid #3b82f6',
                borderRadius: '50%',
                width: '40px',
                height: '40px',
                animation: 'spin 1s linear infinite',
                margin: '0 auto'
              }}></div>
            </div>
            <p style={{ margin: 0, fontSize: '1rem', color: '#374151' }}>
              {processingMessage || 'Processando entrevista...'}
            </p>
          </div>
        </div>
      )}
    </div>
  );
}

export default RecordPage;
